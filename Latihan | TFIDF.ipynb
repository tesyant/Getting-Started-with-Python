{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tesyant/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = TextBlob(\"Tesya Nurintan is an Informatics student at UIN Sunan Kalijaga Yogyakarta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tesya', 'NNP'),\n",
       " ('Nurintan', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('Informatics', 'JJ'),\n",
       " ('student', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('UIN', 'NNP'),\n",
       " ('Sunan', 'NNP'),\n",
       " ('Kalijaga', 'NNP'),\n",
       " ('Yogyakarta', 'NNP')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/tesyant/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['tesya nurintan', 'informatics', 'uin sunan kalijaga yogyakarta'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimonial = TextBlob(\"These clothes are gorgeous! I really want to buy it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.5375, subjectivity=0.55)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikip = TextBlob(\"I am a student at UIN Sunan Kalijaga. \"\n",
    "        \"I study informatics, it's similar to computer science. \"\n",
    "        \"I'm doing my homework about python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'am', 'a', 'student', 'at', 'UIN', 'Sunan', 'Kalijaga', 'I', 'study', 'informatics', 'it', \"'s\", 'similar', 'to', 'computer', 'science', 'I', \"'m\", 'doing', 'my', 'homework', 'about', 'python'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikip.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I am a student at UIN Sunan Kalijaga.\"),\n",
       " Sentence(\"I study informatics, it's similar to computer science.\"),\n",
       " Sentence(\"I'm doing my homework about python\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikip.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=0.0, subjectivity=0.4)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "for sentences in wikip.sentences:\n",
    "    print(sentences.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = TextBlob('Users 4 spaces identation level.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Users', '4', 'spaces', 'identation', 'level'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[0].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'identations'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-2].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/tesyant/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"octopi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"went\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.wordnet import VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = Word(\"octopus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('octopus.n.01'), Synset('octopus.n.02')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tentacles of octopus prepared as food',\n",
       " 'bottom-living cephalopod having a soft oval body with eight long tentacles']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"octopus\").definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.wordnet import Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octopus=Synset('octopus.n.02')\n",
    "shrimp=Synset('shrimp.n.03')\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = TextBlob(\"cat dog octopus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cat', 'dog', 'octopus'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cats', 'dogs', 'octopodes'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "b=TextBlob(\"I havv good speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"faluibilit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "                \"We are now the Knights who say Ekki ekki ekki PTANG. \")\n",
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.noun_phrases.count('Ni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_blob = TextBlob(u'Simple is better than complex.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Lo simple es mejor que lo complejo.\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob.translate(to='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_blob=TextBlob(u\"美丽优于丑陋\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beauty is better than ugly\")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TextBlob(u\"بسيط هو أفضل من مجمع\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TextBlob(\"And now for something completely different.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we went to market'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Word(\"we went to market\")\n",
    "b.lemmatize('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Dengan NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\" Andrea Dovizioso kembali harus merelakan gelar juara dunia MotoGP jatuh ke tangan Marc Marquez.\n",
    "Dovizioso percaya musim depan kans Ducati akan lebih baik.\n",
    "Dovizioso kembali gagal dalam perebutan gelar juara dunia musim ini.\n",
    "Titel direbut oleh Marc Marquez usai juara di Jepang, sementara Dovizioso finis ke-18 di seri ini.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "Hjkt = re.sub(\"(?<!\\d)[.,;:](?!\\d)\", \" \", text)\n",
    "JKata = len(word_tokenize(Hjkt))\n",
    "print(JKata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Andrea Dovizioso kembali harus merelakan gelar juara dunia MotoGP jatuh ke tangan Marc Marquez.',\n",
       " 'Dovizioso percaya musim depan kans Ducati akan lebih baik.',\n",
       " 'Dovizioso kembali gagal dalam perebutan gelar juara dunia musim ini.',\n",
       " 'Titel direbut oleh Marc Marquez usai juara di Jepang, sementara Dovizioso finis ke-18 di seri ini.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PchKal = sent_tokenize(text)\n",
    "PchKal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andrea', 'dovizioso', 'kembali', 'harus', 'merelakan', 'gelar', 'juara', 'dunia', 'motogp', 'jatuh', 'ke', 'tangan', 'marc', 'marquez']\n",
      "14\n",
      "['dovizioso', 'percaya', 'musim', 'depan', 'kans', 'ducati', 'akan', 'lebih', 'baik']\n",
      "9\n",
      "['dovizioso', 'kembali', 'gagal', 'dalam', 'perebutan', 'gelar', 'juara', 'dunia', 'musim', 'ini']\n",
      "10\n",
      "['titel', 'direbut', 'oleh', 'marc', 'marquez', 'usai', 'juara', 'di', 'jepang', 'sementara', 'dovizioso', 'finis', 'ke-18', 'di', 'seri', 'ini']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    TCln = re.sub(\"(?<!\\d)[.,:;](?!\\d)\", \" \", PchKal[i])\n",
    "    TCln = TCln.lower()\n",
    "    JN = len(word_tokenize(TCln))\n",
    "    print(word_tokenize(TCln))\n",
    "    print(JN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def tf(word,blob):\n",
    "    return word_tokenize(blob).count(word)/len(word_tokenize(blob))\n",
    "\n",
    "def n_containing(word,bloblist):\n",
    "    return sum(1 for blob in bloblist if word in word_tokenize(blob))\n",
    "\n",
    "def idf(word,bloblist):\n",
    "    return math.log(len(bloblist)/(1+n_containing(word,bloblist)))\n",
    "\n",
    "def tfidf(word,blob,bloblist):\n",
    "    return tf(word,blob)*idf(word,bloblist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat ke-1\n",
      "Kalimat :   Andrea Dovizioso kembali harus merelakan gelar juara dunia MotoGP jatuh ke tangan Marc Marquez.\n",
      "Jumlah kata dalam kalimat ke 1 adalah 15 \n",
      "Jumlah bobot per kalimat :  0.41936270841190154\n",
      "Jumlah bobot kalimat :  0\n",
      "Bobot TF-IDF Normalisasi :  0.008558422620651053\n",
      "\n",
      "Kalimat ke-2\n",
      "Kalimat :  Dovizioso percaya musim depan kans Ducati akan lebih baik.\n",
      "Jumlah kata dalam kalimat ke 2 adalah 10 \n",
      "Jumlah bobot per kalimat :  0.5139712336371398\n",
      "Jumlah bobot kalimat :  0\n",
      "Bobot TF-IDF Normalisasi :  0.010489208849737548\n",
      "\n",
      "Kalimat ke-3\n",
      "Kalimat :  Dovizioso kembali gagal dalam perebutan gelar juara dunia musim ini.\n",
      "Jumlah kata dalam kalimat ke 3 adalah 11 \n",
      "Jumlah bobot per kalimat :  0.31980471853988546\n",
      "Jumlah bobot kalimat :  0\n",
      "Bobot TF-IDF Normalisasi :  0.006526626908977254\n",
      "\n",
      "Kalimat ke-4\n",
      "Kalimat :  Titel direbut oleh Marc Marquez usai juara di Jepang, sementara Dovizioso finis ke-18 di seri ini.\n",
      "Jumlah kata dalam kalimat ke 4 adalah 17 \n",
      "Jumlah bobot per kalimat :  0.5100451324485936\n",
      "Jumlah bobot kalimat :  0\n",
      "Bobot TF-IDF Normalisasi :  0.010409084335685584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TBList = PchKal\n",
    "BobNrmi=[]\n",
    "for i, blob in enumerate(TBList):\n",
    "    N=0\n",
    "    JBobot=0\n",
    "    RerBbt=0\n",
    "    BobNrm=0\n",
    "    print(\"Kalimat ke-{}\".format(i+1))\n",
    "    scores = {word: tfidf(word,blob,TBList) for word in word_tokenize(blob)}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words:\n",
    "        if score>0:\n",
    "            JBobot = JBobot+score\n",
    "    N = len(sorted_words)\n",
    "    RerBt = JBobot/N\n",
    "    BobNrm = JBobot/JKata\n",
    "    print(\"Kalimat : \", TBList[i])\n",
    "    print(\"Jumlah kata dalam kalimat ke {} adalah {} \".format((i+1),N))\n",
    "    print(\"Jumlah bobot per kalimat : \",JBobot)\n",
    "    print(\"Jumlah bobot kalimat : \",RerBbt)\n",
    "    print(\"Bobot TF-IDF Normalisasi : \",BobNrm)\n",
    "    BobNrmi.append(BobNrm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
